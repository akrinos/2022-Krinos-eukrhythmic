{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine\n",
    "from datetime import date\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "from upsetplot import from_memberships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLOBAL PARAMETERS ##\n",
    "base_dir = \"/vortexfs1/omics/alexander/akrinos/2021-testing-eukrhythmic/eukrhythmic_paper_trials_September21\"\n",
    "eukulele_dir_designer = \"EUKulele_designer\"\n",
    "eukulele_dir_CAG = \"EUKulele_07-CAG\"\n",
    "eukulele_dir_MAD = \"EUKulele_12-MAD\"\n",
    "salmon_dir = os.path.join(base_dir,\"08-salmon_mapping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTIONS ##\n",
    "\n",
    "def read_eggnog_annots(chosen_dir, chosen_community):\n",
    "    eggnog_all = pd.DataFrame()\n",
    "    ### SMALL-SCALE EXAMPLE - community 1, trial 1, 100k ####\n",
    "    eggnog_designer = pd.read_csv(os.path.join(base_dir, chosen_dir, \"eggnog_designer\", \n",
    "                       \"designer_assembly_\" + str(chosen_community) + \".emapper.annotations\"),\n",
    "                                  sep=\"\\t\",comment=\"#\",\n",
    "                            header=None,names=[\"query\",\"seed_ortholog\",\"evalue\",\"score\",\n",
    "                                               \"eggNOG_OGs\",\"max_annot_lvl\",\"COG_category\",\n",
    "                                               \"Description\",\"Preferred_name\",\"GOs\",\"EC\",\"KEGG_ko\",\n",
    "                                               \"KEGG_Pathway\",\"KEGG_Module\",\"KEGG_Reaction\",\"KEGG_rclass\",\n",
    "                                               \"BRITE\",\"KEGG_TC\",\"CAZy\",\"BiGG_Reaction\",\"PFAMs\"])\n",
    "    eggnog_designer[\"Source\"] = \"Designer\"\n",
    "    eggnog_all = pd.concat([eggnog_all,eggnog_designer])\n",
    "    eggnog_CAG = pd.read_csv(os.path.join(base_dir, chosen_dir, \"eggnog_CAG\", \n",
    "                       \"sim_raw_reads_\" + str(chosen_community) + \".emapper.annotations\"),\n",
    "                             sep=\"\\t\",comment=\"#\",\n",
    "                            header=None,names=[\"query\",\"seed_ortholog\",\"evalue\",\"score\",\n",
    "                                               \"eggNOG_OGs\",\"max_annot_lvl\",\"COG_category\",\n",
    "                                               \"Description\",\"Preferred_name\",\"GOs\",\"EC\",\"KEGG_ko\",\n",
    "                                               \"KEGG_Pathway\",\"KEGG_Module\",\"KEGG_Reaction\",\"KEGG_rclass\",\n",
    "                                               \"BRITE\",\"KEGG_TC\",\"CAZy\",\"BiGG_Reaction\",\"PFAMs\"])\n",
    "    eggnog_CAG[\"Source\"] = \"CAG\"\n",
    "    eggnog_all = pd.concat([eggnog_all,eggnog_CAG])\n",
    "    assemblers = [\"spades\",\"rnaspades\",\"trinity\",\"megahit\"]\n",
    "    eggnog_all_assemblers = pd.DataFrame()\n",
    "    for assembler in assemblers:\n",
    "        eggnog_assembler = pd.read_csv(os.path.join(base_dir, chosen_dir, \"eggnog_assembler\", \n",
    "                       \"sim_raw_reads_\" + str(chosen_community) + \"_\" + str(assembler) + \".emapper.annotations\"),\n",
    "                                       sep=\"\\t\",comment=\"#\",\n",
    "                            header=None,names=[\"query\",\"seed_ortholog\",\"evalue\",\"score\",\n",
    "                                               \"eggNOG_OGs\",\"max_annot_lvl\",\"COG_category\",\n",
    "                                               \"Description\",\"Preferred_name\",\"GOs\",\"EC\",\"KEGG_ko\",\n",
    "                                               \"KEGG_Pathway\",\"KEGG_Module\",\"KEGG_Reaction\",\"KEGG_rclass\",\n",
    "                                               \"BRITE\",\"KEGG_TC\",\"CAZy\",\"BiGG_Reaction\",\"PFAMs\"])\n",
    "        \n",
    "        eggnog_assembler[\"Source\"] = assembler\n",
    "        eggnog_all = pd.concat([eggnog_all,eggnog_assembler])\n",
    "    \n",
    "    eggnog_all[\"jEUKebox\"] = chosen_dir\n",
    "    if \"100k\" in chosen_dir:\n",
    "        eggnog_all[\"MMETSPGroup\"] = \"A\"\n",
    "    else:\n",
    "        eggnog_all[\"MMETSPGroup\"] = \"B\"\n",
    "        \n",
    "    return eggnog_all\n",
    "\n",
    "def compute_sourmash_index(sourmash_file, community_file):\n",
    "    sourmash_file_T = sourmash_file.copy()\n",
    "    sourmash_file_T.columns = [curr.split(\"/\")[-1] for curr in sourmash_file.columns]\n",
    "    sourmash_file_T[\"Protein_Files_Split\"] = sourmash_file_T.columns\n",
    "    community_file[\"Protein_Files_Split\"] = [curr.split(\"/\")[-1] for curr in community_file.Protein_Files] \n",
    "    community_file = community_file.groupby([\"Community\",\"Protein_Files_Split\"])[\"Proportion\"].sum().reset_index()\n",
    "    trad_diversity = community_file.groupby(\"Community\")[\"Proportion\"].\\\n",
    "                        agg([lambda x: -np.sum(x * np.log(x)), len]).reset_index()\n",
    "    trad_diversity.columns = [\"Community\",\"Shannon\",\"Richness\"]\n",
    "    \n",
    "    cols_select = [\"Community\",\"Proportion\",\"Protein_Files_Split\"]\n",
    "    cols_select.extend([curr.split(\"/\")[-1] for curr in sourmash_file.columns])\n",
    "    merged_file = community_file.merge(sourmash_file_T,\n",
    "                                       left_on=\"Protein_Files_Split\",\n",
    "                                       right_on=\"Protein_Files_Split\",\n",
    "                                       how=\"left\")[cols_select]\n",
    "    \n",
    "    wide_to_long_merged = pd.wide_to_long(merged_file,stubnames=\"MMETSP\",\n",
    "                i=[\"Community\",\"Proportion\",\"Protein_Files_Split\"],sep=\"\",\n",
    "                j=\"MMETSP_id\",suffix='\\w+_clean.pep.fa').reset_index() \n",
    "    wide_to_long_merged.MMETSP_id = [\"MMETSP\" + curr for curr in wide_to_long_merged.MMETSP_id]\n",
    "    \n",
    "    community_file_join = community_file.copy()[[\"Protein_Files_Split\",\"Proportion\"]]\n",
    "    community_file_join.columns = [\"Joined_ID\",\"Joined_ID_prop\"]\n",
    "\n",
    "    combined_merged = wide_to_long_merged.merge(community_file_join,\n",
    "                              right_on=\"Joined_ID\",\n",
    "                              left_on=\"MMETSP_id\",how=\"right\")\n",
    "    \n",
    "    combined_merged[\"Score\"] = [(1-sourmash) * min(prop1,prop2) for sourmash,prop1,prop2 in \\\n",
    "                        zip(combined_merged.MMETSP, combined_merged.Proportion,\\\n",
    "                        combined_merged.Joined_ID_prop)]\n",
    "    \n",
    "    final_scores = combined_merged.groupby(\"Community\").sum().reset_index().merge(trad_diversity,how=\"inner\")\n",
    "    \n",
    "    return final_scores\n",
    "\n",
    "# Creates a dataframe that is the processed result for this community of clustering\n",
    "# the designer proteins with the reassembled products from eukrhythmic\n",
    "def cluster_sim_designer(cluster_file):\n",
    "    clust_designer = pd.read_csv(cluster_file, sep = \"\\t\",\n",
    "                             header = None, names = [\"Representative\",\"Member\"])\n",
    "    \n",
    "    clust_designer[\"RepresentativeType\"] = [\"designer\" if \"CAMPEP\" in curr else \"reassembled\" if \"sim_raw_reads\" in\\\n",
    "                                            curr else \"indeterminate\" for curr in clust_designer.Representative]\n",
    "    clust_designer[\"MemberType\"] = [\"designer\" if \"CAMPEP\" in curr else \"reassembled\" if \"sim_raw_reads\" in\\\n",
    "                                            curr else \"indeterminate\" for curr in clust_designer.Member]\n",
    "    \n",
    "    def to_set(x):\n",
    "        return set(x)\n",
    "\n",
    "    def length_set(x):\n",
    "        return len(set(x))\n",
    "\n",
    "    clust_designer_sets = clust_designer.groupby(\"Representative\").agg({\"MemberType\": to_set}).reset_index()\n",
    "\n",
    "    conditions = [\n",
    "        (clust_designer_sets[\"MemberType\"] == set({\"designer\",\"reassembled\"})),\n",
    "        (clust_designer_sets[\"MemberType\"] == set({\"designer\"})),\n",
    "        (clust_designer_sets[\"MemberType\"] == set({\"reassembled\"})),\n",
    "    ]\n",
    "    choices = [\"both\",\"designer\",\"reassembled\"]\n",
    "\n",
    "    clust_designer_sets[\"GroupType\"] = np.select(conditions, choices)\n",
    "    combined_result = clust_designer_sets.merge(clust_designer, \n",
    "                                                left_on=\"Representative\",\n",
    "                                                right_on=\"Representative\", how=\"outer\")\n",
    "\n",
    "    combined_result[\"id_shortened\"] = [curr.split(\".p1\")[0] + \".p1\" if \".p1\" in curr \\\n",
    "                                         else curr.split(\".p2\")[0] + \".p2\" if \".p2\" in curr \\\n",
    "                                         else curr.split(\".p3\")[0] + \".p3\" if \".p3\" in curr \\\n",
    "                                         else curr.split(\".p4\")[0] + \".p4\" if \".p4\" in curr \\\n",
    "                                         else curr.split(\".p5\")[0] + \".p5\" if \".p5\" in curr \\\n",
    "                                         else curr.split(\".p6\")[0] + \".p6\" if \".p6\" in curr \\\n",
    "                                         else curr.split(\".p7\")[0] + \".p7\" if \".p7\" in curr \\\n",
    "                                         else curr for curr in combined_result.Member]\n",
    "    return combined_result\n",
    "\n",
    "# convert assembler clusters to well-defined names\n",
    "def convert_names(eggnog_file, cluster_result):\n",
    "    if eggnog_file is None:\n",
    "        return eggnog_file\n",
    "    eggnog_file[\"no_ext\"] = [curr.split(\".\")[0] for curr in eggnog_file[\"query\"]]\n",
    "\n",
    "    def to_set(x):\n",
    "        return set(x)\n",
    "\n",
    "    def length_set(x):\n",
    "        return len(set(x))\n",
    "\n",
    "    eggnog_clust_informed = cluster_result.merge(eggnog_file, left_on = [\"Member\",\"Community\",\"Name\"],\n",
    "                                                 right_on = [\"no_ext\",\"Community\",\"Name\"],\n",
    "                                                 how = \"left\")\\\n",
    "                           .groupby([\"Representative\",\"Community\",\"Name\"])\\\n",
    "                           .agg({\"Assembler_Mem\": to_set}).reset_index()\n",
    "\n",
    "    conditions = [\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"megahit\",\"trinity\",\"spades\",\"rnaspades\"})),\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"megahit\",\"trinity\"})),\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"spades\",\"rnaspades\"})),\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"trinity\",\"rnaspades\"})),\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"rnaspades\"})),\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"trinity\"})),\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"megahit\"})),\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"spades\"})),\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"spades\",\"rnaspades\",\"trinity\"})),\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"spades\",\"rnaspades\",\"megahit\"})),\n",
    "        (eggnog_clust_informed[\"Assembler_Mem\"] == set({\"rnaspades\",\"megahit\"})),\n",
    "        ([len(curr) == 3 for curr in eggnog_clust_informed[\"Assembler_Mem\"]]),\n",
    "        ([len(curr) == 2 for curr in eggnog_clust_informed[\"Assembler_Mem\"]]),\n",
    "    ]\n",
    "    choices = [\"all\",\"MT\",\"SR\",\"TR\",\"R\",\"T\",\"M\",\"S\",\"SRT\",\"SRM\",\"RM\",\"other3\",\"other2\"]\n",
    "\n",
    "    eggnog_clust_informed[\"GroupType\"] = np.select(conditions, choices)\n",
    "    \n",
    "    return eggnog_clust_informed\n",
    "\n",
    "# Read in annotations from eggNOG-mapper.\n",
    "def read_eggnog_results(base_dir, jeukebox_dir, eggnog_dir, eggnog_prefix, sim_file,\n",
    "                        eggnog_names, read_salmon = True, \n",
    "                        salmon_stub = \"sim_raw_reads_\", \n",
    "                        is_prot = False,\n",
    "                        prot_dict = None,\n",
    "                        salmon_dir = os.path.join(\"eukrhythmic_assembly\",\n",
    "                                                                                     \"intermediate-files\",\n",
    "                                                                                     \"04-compare\",\n",
    "                                                                                     \"09-CAG-mapping\",\n",
    "                                                                                     \"salmon\")):\n",
    "    number_file = sim_file.split(\"_merged\")[0].split(\"_\")[-1]\n",
    "    if read_salmon:\n",
    "        if salmon_dir is not None:\n",
    "            if \"09-CAG-mapping\" in salmon_dir:\n",
    "                salmon_dir = os.path.join(base_dir, jeukebox_dir, salmon_dir)\n",
    "                \n",
    "            \n",
    "            if os.path.isfile(os.path.join(salmon_dir,str(number_file) + \"_quant\",\n",
    "                                 \"quant.sf\")):\n",
    "                salmon_file = pd.read_csv(os.path.join(salmon_dir,str(number_file) + \"_quant\",\n",
    "                                     \"quant.sf\"), sep = \"\\t\")\n",
    "                salmon_file[\"NewName\"] = [str(curr).split(\"_flag\")[0].split(\"_len=\")[0] \\\n",
    "                                          for curr in salmon_file[\"Name\"]]\n",
    "            elif not os.path.isfile(os.path.join(salmon_dir,salmon_stub + str(number_file) + \"_quant\",\n",
    "                                 \"quant.sf\")):\n",
    "                read_salmon = False\n",
    "            else:\n",
    "                salmon_file = pd.read_csv(os.path.join(salmon_dir,salmon_stub + str(number_file) + \"_quant\",\n",
    "                                     \"quant.sf\"), sep = \"\\t\")\n",
    "                salmon_file[\"NewName\"] = [str(curr).split(\"_flag\")[0].split(\"_len=\")[0] \\\n",
    "                                          for curr in salmon_file[\"Name\"]]\n",
    "                #salmon_file[\"NewName\"] = [\"_sim_raw_reads\".join(curr.split(\"_sim_raw_reads\")[0:2]) for curr \\\n",
    "                #                          in salmon_file[\"NewName\"]]\n",
    "            \n",
    "    em_file_path = os.path.join(base_dir, jeukebox_dir,\n",
    "                               eggnog_dir, eggnog_prefix + \\\n",
    "                               str(sim_file.split(\"_merged\")[0].split(\"_\")[-1]) +\n",
    "                               \".emapper.annotations\")\n",
    "    if os.path.isfile(em_file_path):\n",
    "        eggnog_curr = pd.read_csv(em_file_path, \n",
    "                                  sep = \"\\t\", comment = \"#\", header = None, names = eggnog_names)\n",
    "        \n",
    "        eggnog_curr[\"Community\"] = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "        eggnog_curr[\"Name\"] = jeukebox_dir\n",
    "        if read_salmon:\n",
    "            if is_prot:\n",
    "                salmon_file = salmon_file.rename(columns={\"Name\":\"nucl_query\"})\n",
    "                eggnog_curr[\"nucl_query\"] = [prot_dict[curr] for curr in eggnog_curr[\"query\"]]\n",
    "                eggnog_curr = eggnog_curr.merge(salmon_file, left_on = \"nucl_query\", right_on = \"nucl_query\")\n",
    "            else:\n",
    "                salmon_file = salmon_file.rename(columns={\"Name\":\"query\"})\n",
    "                eggnog_curr[\"query\"] = [curr.split(\".\")[0] for curr in eggnog_curr[\"query\"]]\n",
    "                eggnog_curr = eggnog_curr.merge(salmon_file, left_on = \"query\", right_on = \"query\")\n",
    "        return eggnog_curr\n",
    "    return None\n",
    "\n",
    "# Read in EUKulele annotations with salmon quantification.\n",
    "def read_EUKulele_annotations(base_dir, jeukebox_dir, eukulele_dir, sim_file,\n",
    "                              filename_stub = \"sim_raw_reads_\", suffix = \"_merged\", salmon_stub = \"sim_raw_reads_\",\n",
    "                              salmon_dir = os.path.join(\"eukrhythmic_assembly\",\"intermediate-files\",\n",
    "                      \"04-compare\",\"09-CAG-mapping\",\"salmon\")):\n",
    "    if salmon_dir is not None:\n",
    "        if \"09-CAG-mapping\" in salmon_dir:\n",
    "            salmon_dir = os.path.join(base_dir, jeukebox_dir, salmon_dir)\n",
    "    if os.path.isdir(os.path.join(base_dir, jeukebox_dir, eukulele_dir)):\n",
    "        if salmon_dir is not None:\n",
    "            if not os.path.isdir(salmon_dir):\n",
    "                return pd.DataFrame()\n",
    "        number_file = sim_file.split(\"_merged\")[0].split(\"_\")[-1]\n",
    "        if not os.path.isfile(os.path.join(base_dir, jeukebox_dir, eukulele_dir,\n",
    "                                                \"taxonomy_estimation\", filename_stub + \\\n",
    "                                                 str(sim_file.split(\"_merged\")[0].split(\"_\")[-1]) +\\\n",
    "                                                suffix + \"-estimated-taxonomy.out\")):\n",
    "            return pd.DataFrame()\n",
    "        EUKulele_CAG = pd.read_csv(os.path.join(base_dir, jeukebox_dir, eukulele_dir,\n",
    "                                                \"taxonomy_estimation\", filename_stub + \\\n",
    "                                                 str(sim_file.split(\"_merged\")[0].split(\"_\")[-1]) +\\\n",
    "                                                suffix + \"-estimated-taxonomy.out\"), sep = \"\\t\")\n",
    "        if salmon_dir is not None:\n",
    "            salmon_file = pd.read_csv(os.path.join(salmon_dir,salmon_stub + str(number_file) + \"_quant\",\n",
    "                                 \"quant.sf\"), sep = \"\\t\")\n",
    "            salmon_file[\"NewName\"] = [str(curr).split(\"_flag\")[0].split(\"_len=\")[0] \\\n",
    "                                      for curr in salmon_file[\"Name\"]]\n",
    "            salmon_file[\"NewName\"] = [\"_sim_raw_reads\".join(curr.split(\"_sim_raw_reads\")[0:2]) for curr \\\n",
    "                                      in salmon_file[\"NewName\"]]\n",
    "            EUKulele_CAG = pd.merge(left = salmon_file, right = EUKulele_CAG, how = \"outer\",\n",
    "                                    left_on = \"Name\", right_on = \"transcript_name\")\n",
    "            EUKulele_CAG[\"PivotName\"] = EUKulele_CAG[\"Name\"]\n",
    "        else:\n",
    "            EUKulele_CAG[\"PivotName\"] = EUKulele_CAG[\"transcript_name\"]\n",
    "\n",
    "        EUKulele_CAG[\"Community\"] = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "        EUKulele_CAG[\"Name\"] = jeukebox_dir\n",
    "        EUKulele_CAG[\"Assembler\"] = [str(curr).split(\"_\")[0] if curr == curr else \\\n",
    "                                     \"None\" for curr in EUKulele_CAG.PivotName]\n",
    "\n",
    "        EUKulele_CAG[[\"Domain\",\"Supergroup\",\"Phylum\",\"Class\",\"Order\",\n",
    "                    \"Family\",\"Genus\",\"Species\"]]= EUKulele_CAG[\"full_classification\"].\\\n",
    "                                            str.split(\";\", n = 8, expand = True)\n",
    "        EUKulele_CAG[[\"Domain\",\"Supergroup\",\"Phylum\",\"Class\",\\\n",
    "                  \"Family\",\"Genus\",\"Species\",\"classification\"]] = EUKulele_CAG[[\"Domain\",\"Supergroup\",\"Phylum\",\"Class\",\\\n",
    "                  \"Family\",\"Genus\",\"Species\",\"classification\"]].fillna(value=\"Unannotated\")\n",
    "        \n",
    "        EUKulele_CAG[\"Community\"] = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "        EUKulele_CAG[\"Name\"] = jeukebox_dir\n",
    "        return EUKulele_CAG\n",
    "    \n",
    "def format_sim_des(clust_designer):\n",
    "    clust_designer[\"RepresentativeType\"] = [\"designer\" if \"CAMPEP\" in curr else \"reassembled\" if \"sim_raw_reads\" in\\\n",
    "                                        curr else \"indeterminate\" for curr in clust_designer.Representative]\n",
    "    clust_designer[\"MemberType\"] = [\"designer\" if \"CAMPEP\" in curr else \"reassembled\" if \"sim_raw_reads\" in\\\n",
    "                                        curr else \"indeterminate\" for curr in clust_designer.Member]\n",
    "    \n",
    "    return clust_designer\n",
    "\n",
    "# compare identified GO terms to the designer assembly.\n",
    "def compare_to_designer_go(eggnog_designer_curr, final_res_GOs):\n",
    "    eggnog_designer_curr[\"GOs\"] = [curr.split(\",\") for curr in eggnog_designer_curr.GOs]\n",
    "    eggnog_designer_curr = eggnog_designer_curr.explode(\"GOs\")\n",
    "    eggnog_designer_GOs = eggnog_designer_curr.groupby([\"GOs\"])[\"query\"].count().reset_index()\n",
    "    eggnog_designer_GOs = eggnog_designer_GOs.rename({\"query\":\"DesignerCount\"},axis=\"columns\")\n",
    "    \n",
    "    final_res_GOs = final_res_GOs.groupby([\"Community\",\"Name\",\"GOs\",\n",
    "                                           \"AssemblerCluster\",\"SimDesignerCluster\"])[\"query\"].count().\\\n",
    "        reset_index()\n",
    "    final_res_GOs = final_res_GOs.rename({\"query\":\"CAGCount\"},axis=\"columns\")\n",
    "    \n",
    "    to_return = eggnog_designer_GOs.merge(final_res_GOs, left_on = [\"GOs\"],\n",
    "                                     right_on = [\"GOs\"],\n",
    "                              how = \"outer\").fillna(0)\n",
    "    \n",
    "    to_return[\"Name\"] = list(set(eggnog_designer_curr[\"Name\"]))[0]\n",
    "    to_return[\"Community\"] = list(set(eggnog_designer_curr[\"Community\"]))[0]\n",
    "    to_return.loc[to_return.AssemblerCluster == 0, [\"AssemblerCluster\",\"SimDesignerCluster\"]] = \"none\"\n",
    "    \n",
    "    return to_return\n",
    "\n",
    "# compare identified KO pathways combined with cluster info.\n",
    "def compare_designer_clusts(eggnog_designer_curr, \n",
    "                            cluster_file,\n",
    "                            final_res, functional=\"KEGG_Pathway\"):\n",
    "    eggnog_designer_curr[functional] = [curr.split(\",\") if\\\n",
    "                                        type(curr) != list \\\n",
    "                                        else curr for curr in eggnog_designer_curr[functional]]\n",
    "    eggnog_designer_curr = eggnog_designer_curr.explode(functional)\n",
    "    eggnog_designer_fct = eggnog_designer_curr.rename({\"query\":\"DesignerQuery\",\n",
    "                                                       functional:\"Designer_\"+functional},axis=\"columns\")\n",
    "    cluster_file[\"MemberSplit\"] = [curr.split(\"_/\")[0] for curr in cluster_file[\"Member\"]]\n",
    "    eggnog_designer_fct = eggnog_designer_fct.merge(cluster_file, left_on = \"DesignerQuery\",\n",
    "                                                    right_on = \"MemberSplit\", how = \"left\")\n",
    "    \n",
    "    final_res = final_res.rename({\"query\":\"CAGQuery\",functional:\"CAG_\"+functional},axis=\"columns\")\n",
    "    #final_res = final_res.merge(cluster_file, left_on = \"CAGQuery\",\n",
    "    #                            right_on = \"Member\", how = \"left\")\n",
    "    \n",
    "    #return final_res\n",
    "    to_return = eggnog_designer_fct[[\"Name\",\"Community\",\"Representative\",\n",
    "                                    \"DesignerQuery\",\"Designer_\"+functional]].merge(final_res[[\"Name\",\n",
    "                                                                                              \"Community\",\n",
    "                                                                                              \"Representative\",\n",
    "                                                                                              \"CAGQuery\",\n",
    "                                                                                              \"CAG_\"+functional]],\n",
    "                                                                                  left_on = [\"Representative\",\n",
    "                                                                                             \"Name\",\"Community\"],\n",
    "                                          right_on = [\"Representative\",\"Name\",\"Community\"],\n",
    "                              how = \"inner\").fillna(0)\n",
    "    def create_list(x):\n",
    "        return sorted(list(set(x)))\n",
    "    return to_return[[\"Name\",\"Community\",\"Representative\",\"CAGQuery\",\"DesignerQuery\",\"Designer_\"+functional,\n",
    "                      \"CAG_\"+functional]].groupby([\"Name\",\"Community\",\"Representative\"]).\\\n",
    "            agg({\"Designer_\"+functional: create_list, \"CAG_\"+functional: create_list})\n",
    "\n",
    "def compare_designer_clusts_eukulele(EUKulele_designer_curr, \n",
    "                            cluster_file,\n",
    "                            final_res, tax_level = \"Genus\"):\n",
    "    EUKulele_designer_curr = EUKulele_designer_curr.rename({tax_level:\"Designer_\" + tax_level},\n",
    "                                                           axis=\"columns\")\n",
    "    cluster_file[\"MemberSplit\"] = [curr.split(\"_/\")[0].split(\".p\")[0] for curr in cluster_file[\"Member\"]]\n",
    "    EUKulele_designer_curr = EUKulele_designer_curr.merge(cluster_file, left_on = \"transcript_name\",\n",
    "                                                          right_on = \"MemberSplit\", how = \"inner\")\n",
    "    \n",
    "    final_res = final_res.rename({tax_level:\"CAG_\"+tax_level},axis=\"columns\")\n",
    "    final_res = final_res.merge(cluster_file, left_on = \"transcript_name\",\n",
    "                                right_on = \"MemberSplit\", how = \"inner\")\n",
    "    #return final_res\n",
    "    to_return = EUKulele_designer_curr[[\"Representative\",\"Name\",\n",
    "                                        \"Community\",\"Designer_\"+tax_level]].merge(final_res[[\"Representative\",\n",
    "                                                                                             \"Name\",\n",
    "                                                                                             \"Community\",\n",
    "                                                                                             \"CAG_\"+tax_level]],\n",
    "                                                       left_on = [\"Representative\",\"Name\",\"Community\"],\n",
    "                                          right_on = [\"Representative\",\"Name\",\"Community\"],\n",
    "                              how = \"inner\").fillna(0)\n",
    "    def create_list(x):\n",
    "        result = sorted(list(set(x)))\n",
    "        if (len(result) == 1):\n",
    "            return result[0].strip()\n",
    "    return to_return[[\"Name\",\"Community\",\"Representative\",\"Designer_\"+tax_level,\n",
    "                      \"CAG_\"+tax_level]].groupby([\"Name\",\"Community\",\"Representative\"]).\\\n",
    "            agg({\"Designer_\"+tax_level: create_list, \"CAG_\"+tax_level: create_list})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jEUKebox-Trial3-CommB passed prot clust\n",
      "jEUKebox-Trial2-CommB passed prot clust\n",
      "jEUKebox-Trial4-100k passed prot clust\n",
      "jEUKebox-Trial2-100k passed prot clust\n",
      "jEUKebox-Trial1-CommB passed prot clust\n",
      "jEUKebox-Trial3-100k passed prot clust\n",
      "jEUKebox-Trial1-100k passed prot clust\n",
      "jEUKebox-Trial4-CommB passed prot clust\n"
     ]
    }
   ],
   "source": [
    "## READ IN EUKRHYTHMIC DATA##\n",
    "jeukebox_dirs = [curr for curr in os.listdir(base_dir) if \"jEUKebox\" in curr]\n",
    "all_results = pd.DataFrame()\n",
    "count_cluster_all = pd.DataFrame()\n",
    "all_go_comparison = pd.DataFrame()\n",
    "all_compared_designer = pd.DataFrame()\n",
    "all_eukulele_compare = pd.DataFrame()\n",
    "all_EUKulele_CAG = pd.DataFrame()\n",
    "all_eukulele_designer = pd.DataFrame()\n",
    "all_clust_designer = pd.DataFrame()\n",
    "all_eggnog_designer = pd.DataFrame()\n",
    "all_eggnog_CAG = pd.DataFrame()\n",
    "eggnog_all = pd.DataFrame()\n",
    "\n",
    "eggnog_names = [\"query\",\"seed_ortholog\",\"evalue\",\"score\",\"eggNOG_OGs\",\"max_annot_lvl\",\"COG_category\",\n",
    "                \"Description\",\"Preferred_name\",\"GOs\",\"EC\",\"KEGG_ko\",\"KEGG_Pathway\",\"KEGG_Module\",\n",
    "                \"KEGG_Reaction\",\"KEGG_rclass\",\"BRITE\",\"KEGG_TC\",\"CAZy\",\"BiGG_Reaction\",\"PFAMs\"]\n",
    "\n",
    "## SAVE DATA ON CLUSTERING, EGGNOG & EUKULELE, AND CLUSTER METADATA ##\n",
    "for jeukebox_dir in jeukebox_dirs:\n",
    "    sourmash_file = os.path.join(base_dir, jeukebox_dir, \"sourmash_MMETSP\", \"all.csv\")\n",
    "    if os.path.isfile(sourmash_file):\n",
    "        \n",
    "        if not os.path.isdir(os.path.join(base_dir, jeukebox_dir, \n",
    "                             \"sourmash_MMETSP\")):\n",
    "            continue\n",
    "        sourmash_file = pd.read_csv(os.path.join(base_dir, jeukebox_dir, \n",
    "                                                 \"sourmash_MMETSP\", \"all.csv\"))\n",
    "        community_file = pd.read_csv(os.path.join(base_dir, jeukebox_dir, \n",
    "                                                  \"03-community_spec\", \"communities.csv\"))\n",
    "        dictionary_protein = dict()\n",
    "        for ind_num in range(len(community_file.index)):\n",
    "            nucl_ids = [r.id for r in SeqIO.parse(community_file.Organism[ind_num], \"fasta\")]\n",
    "            prot_ids = [r.id for r in SeqIO.parse(community_file.Protein_Files[ind_num], \"fasta\")]\n",
    "            dictionary_protein.update(dict(zip(prot_ids,nucl_ids)))\n",
    "        \n",
    "        final_scores = compute_sourmash_index(sourmash_file, community_file)\n",
    "        prot_clust_dir = os.path.join(base_dir, jeukebox_dir,\n",
    "                                      \"eukrhythmic_assembly\",\n",
    "                                      \"intermediate-files\",\n",
    "                                      \"03-merge\", \"07-CAG\")\n",
    "        if not os.path.isdir(prot_clust_dir):\n",
    "            continue\n",
    "            \n",
    "        print(jeukebox_dir,\"passed prot clust\",flush=True)\n",
    "        cluster_results = pd.DataFrame()\n",
    "        for sim_file in os.listdir(prot_clust_dir):\n",
    "            if \"tsv\" not in sim_file:\n",
    "                continue\n",
    "                \n",
    "            ## WHAT'S INSIDE THE CAG FINAL CONTIGS??\n",
    "            cluster_result = pd.read_csv(os.path.join(prot_clust_dir,\n",
    "                                                      sim_file),sep=\"\\t\",\n",
    "                                        header=None,names=[\"Representative\",\"Member\"])\n",
    "            comm_num = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "            cluster_result[\"Community\"] = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "            cluster_result[\"Name\"] = jeukebox_dir\n",
    "            cluster_result[\"Assembler_Rep\"] = [curr.split(\"_\")[0] for curr in cluster_result.Representative]\n",
    "            cluster_result[\"Assembler_Mem\"] = [curr.split(\"_\")[0] for curr in cluster_result.Member]\n",
    "            cluster_results = pd.concat([cluster_results, cluster_result])\n",
    "            \n",
    "            \n",
    "            ## EGGNOG RESULTS\n",
    "            eggnog_designer_curr = read_eggnog_results(base_dir, jeukebox_dir,\n",
    "                                                       eggnog_dir=\"eggnog_designer\",\n",
    "                                                       eggnog_prefix=\"designer_assembly_\",\n",
    "                                                       sim_file=sim_file,\n",
    "                                                       eggnog_names=eggnog_names,\n",
    "                                                       is_prot = True,\n",
    "                                                       prot_dict = dictionary_protein,\n",
    "                                                       salmon_dir = os.path.join(base_dir,jeukebox_dir,\n",
    "                                                                                    \"08-salmon_mapping\"))\n",
    "            \n",
    "            eggnog_all = pd.concat([eggnog_all,read_eggnog_annots(jeukebox_dir, comm_num)])\n",
    "\n",
    "            all_eggnog_designer = pd.concat([all_eggnog_designer,eggnog_designer_curr])\n",
    "            eggnog_CAG_curr = read_eggnog_results(base_dir, jeukebox_dir,\n",
    "                                                   eggnog_dir=\"eggnog_CAG\",\n",
    "                                                   eggnog_prefix=\"sim_raw_reads_\",\n",
    "                                                   sim_file=sim_file,\n",
    "                                                   eggnog_names=eggnog_names,\n",
    "                                                   salmon_dir = os.path.join(base_dir,\n",
    "                                                                             jeukebox_dir,\n",
    "                                                                             \"eukrhythmic_assembly\",\n",
    "                                                                             \"intermediate-files\",\n",
    "                                                                             \"04-compare\",\n",
    "                                                                             \"09-CAG-mapping\",\n",
    "                                                                             \"salmon\"))\n",
    "            all_eggnog_CAG = pd.concat([all_eggnog_CAG,eggnog_CAG_curr])\n",
    "            \n",
    "            # this DataFrame contains the name of every cluster member and the assemblers\n",
    "            # inside of the cluster.\n",
    "            CAG_contig_correspondence = convert_names(eggnog_CAG_curr, cluster_result)\n",
    "            \n",
    "            ## EUKULELE RESULTS\n",
    "            EUKulele_CAG = read_EUKulele_annotations(base_dir, jeukebox_dir, \"EUKulele_CAG_newnames\",\n",
    "                                                     sim_file)\n",
    "            all_EUKulele_CAG = pd.concat([all_EUKulele_CAG,EUKulele_CAG])\n",
    "            \n",
    "            \n",
    "            EUKulele_designer = read_EUKulele_annotations(base_dir, jeukebox_dir, \"EUKulele_designer\", sim_file,\n",
    "                                                          filename_stub = \"designer_assembly_\", suffix = \"\",\n",
    "                                                          salmon_dir = os.path.join(base_dir,jeukebox_dir,\n",
    "                                                                                    \"08-salmon_mapping\"),\n",
    "                                                          salmon_stub = \"\")\n",
    "            \n",
    "            EUKulele_designer[\"Community\"] = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "            EUKulele_designer[\"Name\"] = jeukebox_dir\n",
    "            all_eukulele_designer = pd.concat([all_eukulele_designer,EUKulele_designer])\n",
    "            \n",
    "            EUKulele_designer_noquant = read_EUKulele_annotations(base_dir, jeukebox_dir, \n",
    "                                                                  \"EUKulele_designer\", sim_file,\n",
    "                                                          filename_stub = \"designer_assembly_\", suffix = \".pep\",\n",
    "                                                          salmon_dir = None)\n",
    "            \n",
    "            ## CLUSTERING BETWEEN SIM AND DESIGNER\n",
    "            cluster_file = os.path.join(base_dir, jeukebox_dir, \n",
    "                                                      \"clustering\",\n",
    "                                                      \"clustering_sim_designer\",\n",
    "                                                      \"prot-merge\",\"c_0.95\",\"seqid_0.95\",\n",
    "                                                      \"sim_raw_reads_\" + \\\n",
    "                                                      str(comm_num) + \\\n",
    "                                                      \"_and_designer_assembly_\" + \\\n",
    "                                                      str(comm_num) + \".tsv\")\n",
    "            if os.path.isfile(cluster_file):\n",
    "                clust_designer = cluster_sim_designer(cluster_file)\n",
    "                clust_designer_ret = clust_designer.copy()\n",
    "                clust_designer_ret[\"Community\"] = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "                clust_designer_ret[\"Name\"] = jeukebox_dir\n",
    "                all_clust_designer = pd.concat([all_clust_designer,clust_designer_ret])\n",
    "                if (eggnog_CAG_curr is not None) & (eggnog_designer_curr is not None):\n",
    "                    \n",
    "                    intermediate_cag = eggnog_CAG_curr.merge(clust_designer, left_on = \"query\",\n",
    "                                                             right_on = \"id_shortened\", how = \"left\")\n",
    "                    intermediate_cag[\"id_shortened\"] = [curr.split(\".p\")[0] for curr in intermediate_cag[\"query\"]]\n",
    "\n",
    "                    final_res = intermediate_cag.merge(CAG_contig_correspondence,\n",
    "                                                       left_on = [\"Community\",\"Name\",\"id_shortened\"],\n",
    "                                                       right_on = [\"Community\",\"Name\",\"Representative\"], how = \"left\")\\\n",
    "                                .rename({\"GroupType_x\":\"SimDesignerCluster\",\n",
    "                                         \"GroupType_y\": \"AssemblerCluster\"}, axis='columns')\n",
    "\n",
    "                    count_cluster_type = final_res.groupby([\"SimDesignerCluster\",\"AssemblerCluster\",\n",
    "                                                            \"Name\",\"Community\"])[\"query\"].\\\n",
    "                                                   count().reset_index().pivot(index = \"AssemblerCluster\",\n",
    "                                                                               columns = \"SimDesignerCluster\",\n",
    "                                                                               values = \"query\").reset_index()\n",
    "                    count_cluster_all = pd.concat([count_cluster_all, count_cluster_type])\n",
    "\n",
    "\n",
    "                    final_res[\"GOs\"] = [curr.split(\",\") for curr in final_res.GOs]\n",
    "                    final_res[\"KEGG_Pathway\"] = [curr.split(\",\") for curr in final_res.KEGG_Pathway]\n",
    "                    final_res_GOs = final_res.explode(\"GOs\")\n",
    "                    final_res_KEGG_paths = final_res.explode(\"KEGG_Pathway\")\n",
    "\n",
    "                    ## COMPARE GO TERMS TO DESIGNER GO TERMS\n",
    "                    go_comparison = compare_to_designer_go(eggnog_designer_curr, final_res_GOs)\n",
    "                    all_go_comparison = pd.concat([all_go_comparison,go_comparison])\n",
    "\n",
    "                    intermediate_cag[\"KEGG_Pathway\"] = [curr.split(\",\") for curr in intermediate_cag.KEGG_Pathway]\n",
    "                    intermediate_cag_KEGGs = intermediate_cag.explode(\"KEGG_Pathway\")\n",
    "\n",
    "                    compared_designer = compare_designer_clusts(eggnog_designer_curr,\n",
    "                                                                clust_designer,\n",
    "                                                                intermediate_cag_KEGGs,\n",
    "                                                                functional=\"KEGG_Pathway\")\n",
    "                    all_compared_designer = pd.concat([all_compared_designer,compared_designer])\n",
    "                \n",
    "            if (EUKulele_designer_noquant is not None) & (EUKulele_CAG is not None) &\\\n",
    "               (not EUKulele_designer_noquant.empty):\n",
    "                EUKulele_compare = compare_designer_clusts_eukulele(EUKulele_designer_noquant, \n",
    "                                                                    clust_designer,\n",
    "                                                                    EUKulele_CAG,\n",
    "                                                                    tax_level=\"Genus\").reset_index()\n",
    "                all_eukulele_compare = pd.concat([all_eukulele_compare,EUKulele_compare])\n",
    "        \n",
    "        cluster_results = cluster_results.merge(final_scores,left_on=\"Community\",right_on=\"Community\",how=\"left\")\n",
    "        \n",
    "        all_results = pd.concat([all_results,cluster_results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jEUKebox-Trial3-CommB passed prot clust\n",
      "jEUKebox-Trial2-CommB passed prot clust\n",
      "jEUKebox-Trial4-100k passed prot clust\n",
      "jEUKebox-Trial2-100k passed prot clust\n",
      "jEUKebox-Trial1-CommB passed prot clust\n",
      "jEUKebox-Trial3-100k passed prot clust\n",
      "jEUKebox-Trial1-100k passed prot clust\n",
      "jEUKebox-Trial4-CommB passed prot clust\n"
     ]
    }
   ],
   "source": [
    "## get protein EUKulele annotations for designer\n",
    "eukulele_prot_annots = pd.DataFrame()\n",
    "eggnog_prot_annots = pd.DataFrame()\n",
    "for jeukebox_dir in jeukebox_dirs:\n",
    "    sourmash_file = os.path.join(base_dir, jeukebox_dir, \"sourmash_MMETSP\", \"all.csv\")\n",
    "    if os.path.isfile(sourmash_file):\n",
    "        \n",
    "        if not os.path.isdir(os.path.join(base_dir, jeukebox_dir, \n",
    "                             \"sourmash_MMETSP\")):\n",
    "            continue\n",
    "        #print(jeukebox_dir,\"passed sourmash\",flush=True)\n",
    "        sourmash_file = pd.read_csv(os.path.join(base_dir, jeukebox_dir, \n",
    "                                                 \"sourmash_MMETSP\", \"all.csv\"))\n",
    "        community_file = pd.read_csv(os.path.join(base_dir, jeukebox_dir, \n",
    "                                                  \"03-community_spec\", \"communities.csv\"))\n",
    "        prot_clust_dir = os.path.join(base_dir, jeukebox_dir,\n",
    "                                      \"eukrhythmic_assembly\",\n",
    "                                      \"intermediate-files\",\n",
    "                                      \"03-merge\", \"07-CAG\")\n",
    "        if not os.path.isdir(prot_clust_dir):\n",
    "            continue\n",
    "            \n",
    "        print(jeukebox_dir,\"passed prot clust\",flush=True)\n",
    "        cluster_results = pd.DataFrame()\n",
    "        for sim_file in os.listdir(prot_clust_dir):\n",
    "            #eukulele_prot_annots\n",
    "            \n",
    "            EUKulele_designer = read_EUKulele_annotations(base_dir, jeukebox_dir, \"EUKulele_designer\", sim_file,\n",
    "                                                          filename_stub = \"designer_assembly_\", suffix = \".pep\",\n",
    "                                                          salmon_dir = None)\n",
    "            \n",
    "            eggnog_designer_curr = read_eggnog_results(base_dir, jeukebox_dir,\n",
    "                                                       eggnog_dir=\"eggnog_designer\",\n",
    "                                                       eggnog_prefix=\"designer_assembly_\",\n",
    "                                                       sim_file=sim_file,\n",
    "                                                       eggnog_names=eggnog_names,\n",
    "                                                       read_salmon=False,\n",
    "                                                       salmon_dir = os.path.join(base_dir,jeukebox_dir,\n",
    "                                                                                    \"08-salmon_mapping\"))\n",
    "            \n",
    "            eggnog_designer_curr[\"Community\"] = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "            eggnog_designer_curr[\"Name\"] = jeukebox_dir\n",
    "            \n",
    "            eggnog_prot_annots = pd.concat([eggnog_prot_annots,eggnog_designer_curr])\n",
    "            \n",
    "            EUKulele_designer[\"Community\"] = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "            EUKulele_designer[\"Name\"] = jeukebox_dir\n",
    "            eukulele_prot_annots = pd.concat([eukulele_prot_annots,EUKulele_designer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "designer_species = dict(zip(eukulele_prot_annots.transcript_name, eukulele_prot_annots.Species))\n",
    "designer_genera = dict(zip(eukulele_prot_annots.transcript_name, eukulele_prot_annots.Genus))\n",
    "designer_kos = dict(zip(eggnog_prot_annots[\"query\"],eggnog_prot_annots.KEGG_ko))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "jeukebox_dirs = [curr for curr in os.listdir(base_dir) if \"jEUKebox\" in curr]\n",
    "\n",
    "cag_sizes=pd.DataFrame()\n",
    "designer_sizes=pd.DataFrame()\n",
    "\n",
    "for jeukebox_dir in jeukebox_dirs:\n",
    "    sourmash_file = os.path.join(base_dir, jeukebox_dir, \"sourmash_MMETSP\", \"all.csv\")\n",
    "    #if jeukebox_dir == \"jEUKebox-Trial2-CommB\":\n",
    "    #    continue\n",
    "    #print(jeukebox_dir,\"starting\")\n",
    "    if os.path.isfile(sourmash_file):\n",
    "        \n",
    "        if not os.path.isdir(os.path.join(base_dir, jeukebox_dir, \n",
    "                             \"sourmash_MMETSP\")):\n",
    "            continue\n",
    "        #print(jeukebox_dir,\"passed sourmash\",flush=True)\n",
    "        sourmash_file = pd.read_csv(os.path.join(base_dir, jeukebox_dir, \n",
    "                                                 \"sourmash_MMETSP\", \"all.csv\"))\n",
    "        community_file = pd.read_csv(os.path.join(base_dir, jeukebox_dir, \n",
    "                                                  \"03-community_spec\", \"communities.csv\"))\n",
    "\n",
    "        #print(final_scores,flush=True)\n",
    "        prot_clust_dir = os.path.join(base_dir, jeukebox_dir,\n",
    "                                      \"eukrhythmic_assembly\",\n",
    "                                      \"intermediate-files\",\n",
    "                                      \"03-merge\", \"07-CAG\")\n",
    "        if not os.path.isdir(prot_clust_dir):\n",
    "            continue\n",
    "            \n",
    "        for sim_file in os.listdir(prot_clust_dir):\n",
    "            if \"fasta\" not in sim_file:\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            comm_num = sim_file.split(\"sim_raw_reads_\")[-1].split(\"_\")[0]\n",
    "                \n",
    "            ## STORED CONTIGS FROM DESIGNER ASSEMBLY\n",
    "            designer_contigs = os.path.join(base_dir, jeukebox_dir, \n",
    "                                                      \"06-designer_assemblies\",\n",
    "                                                      \"designer_assembly_\" + str(comm_num) + \".fasta\")\n",
    "            designer_size = os.path.getsize(designer_contigs)\n",
    "            des_length_distro = [len(r.seq) for r in SeqIO.parse(designer_contigs, \"fasta\")]\n",
    "            des_gc_content = [r.seq.count(\"G\") + r.seq.count(\"C\") for r in SeqIO.parse(designer_contigs, \"fasta\")]\n",
    "            des_ids = [r.id for r in SeqIO.parse(designer_contigs, \"fasta\")]\n",
    "            \n",
    "            ## WHAT'S INSIDE THE CAG ASSEMBLY\n",
    "            cag_assembly = os.path.join(prot_clust_dir,sim_file)\n",
    "            cag_length_distro = [len(r.seq) for r in SeqIO.parse(cag_assembly, \"fasta\")]\n",
    "            cag_gc_content = [r.seq.count(\"G\") + r.seq.count(\"C\") for r in SeqIO.parse(cag_assembly, \"fasta\")]\n",
    "            cag_ids = [r.id for r in SeqIO.parse(cag_assembly, \"fasta\")]\n",
    "            cag_size = os.path.getsize(cag_assembly)\n",
    "            \n",
    "            mmetsp_group = \"B\"\n",
    "            if \"100k\" in jeukebox_dir:\n",
    "                mmetsp_group = \"A\"\n",
    "            \n",
    "            curr_df = pd.DataFrame({\"jEUKebox\": [jeukebox_dir] * len(cag_length_distro),\n",
    "                                    \"Representative\": cag_ids,\n",
    "                                    \"Sizes\": cag_length_distro,\n",
    "                                    \"GC\": cag_gc_content,\n",
    "                                    \"Community\": comm_num,\n",
    "                                    \"MMETSPGroup\": mmetsp_group})\n",
    "            cag_sizes = pd.concat([cag_sizes,curr_df])\n",
    "            \n",
    "            \n",
    "            curr_df = pd.DataFrame({\"jEUKebox\": [jeukebox_dir] * len(des_length_distro),\n",
    "                                    \"Representative\": des_ids,\n",
    "                                    \"Sizes\": des_length_distro,\n",
    "                                    \"GC\": des_gc_content,\n",
    "                                    \"Community\": comm_num,\n",
    "                                    \"MMETSPGroup\": mmetsp_group})\n",
    "            designer_sizes = pd.concat([designer_sizes,curr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cag_sizes[\"Community\"] = [int(curr) for curr in cag_sizes[\"Community\"]]\n",
    "\n",
    "designer_sizes[\"Source\"] = \"Designer\"\n",
    "cag_sizes[\"Source\"] = \"Reassembled\"\n",
    "\n",
    "concat_sizes = pd.concat([designer_sizes,cag_sizes])\n",
    "concat_sizes[\"GCFract\"] = concat_sizes[\"GC\"] / concat_sizes[\"Sizes\"]\n",
    "compared_sizes = concat_sizes.groupby([\"MMETSPGroup\",\"Community\",\"Source\"]).describe().reset_index()\n",
    "\n",
    "compared_sizes.columns = [' '.join(col).strip() for col in compared_sizes.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "compared_species = pd.merge(all_eukulele_designer.groupby([\"Genus\",\"Name\",\"Community\"])[\"TPM\"].\\\n",
    "                             sum().reset_index().\\\n",
    "         rename(columns={\"TPM\":\"DesignerGenusTPM\"}),\n",
    "         all_EUKulele_CAG.groupby([\"Genus\",\"Name\",\"Community\"])[\"TPM\"].sum().reset_index().\\\n",
    "         rename(columns={\"TPM\":\"CAGGenusTPM\"}),\n",
    "         left_on=[\"Name\",\"Community\",\"Genus\"],right_on=[\"Name\",\"Community\",\"Genus\"])\n",
    "compared_species[\"MMETSPGroup\"] = [\"A\" if \"100k\" in curr else \"B\" for curr in compared_species[\"Name\"]]\n",
    "compared_species[\"Genus\"] = [curr.strip() for curr in compared_species[\"Genus\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jEUKebox-Trial3-CommB\n",
      "jEUKebox-Trial2-CommB\n",
      "jEUKebox-Trial4-100k\n",
      "jEUKebox-Trial2-100k\n",
      "jEUKebox-Trial1-CommB\n",
      "jEUKebox-Trial3-100k\n",
      "jEUKebox-Trial1-100k\n",
      "jEUKebox-Trial4-CommB\n"
     ]
    }
   ],
   "source": [
    "## GET THE FILE SIZES TO GENERATE TABLES FOR PAPER ##\n",
    "communities = list(range(1,7))\n",
    "file_sizes = pd.DataFrame()\n",
    "jeukebox_dirs = [curr for curr in os.listdir(base_dir) if \"jEUKebox\" in curr]\n",
    "for jeukebox_dir in jeukebox_dirs:\n",
    "    print(jeukebox_dir,flush=True)\n",
    "    for comm_num in communities:\n",
    "        base_dir_covs = os.path.join(base_dir, jeukebox_dir, \"clustering\",\n",
    "                                    \"clustering_designer\",\"prot\")\n",
    "        coverage_dirs = os.listdir(base_dir_covs)\n",
    "        all_seq_files = pd.DataFrame()\n",
    "        for coverage in coverage_dirs:\n",
    "            cov_curr = coverage.split(\"_\")[-1]\n",
    "            seq_ids = os.listdir(os.path.join(base_dir_covs,coverage))\n",
    "            for seq_id in seq_ids:\n",
    "                seq_curr = seq_id.split(\"_\")[-1]\n",
    "                seq_file = os.path.join(base_dir_covs,coverage,\n",
    "                                                                 seq_id,\n",
    "                                                                 \"designer_assembly_\" + \\\n",
    "                                    str(comm_num) + \".pep.fasta\")\n",
    "                contig_no = len([r.id for r in SeqIO.parse(seq_file, \"fasta\")])\n",
    "                kegg_kos = []\n",
    "                [kegg_kos.extend(designer_kos[curr.id].split(\",\")) if curr.id in\\\n",
    "                    designer_kos else \"\" for curr in SeqIO.parse(seq_file, \"fasta\")]\n",
    "                kegg_kos = set(kegg_kos)\n",
    "                genera = set([designer_genera[curr.id].strip() if curr.id in designer_genera \\\n",
    "                               else \"\" for curr in SeqIO.parse(seq_file, \"fasta\")])\n",
    "                genera = list(genera)\n",
    "                genera.remove(\"\")\n",
    "                genera.remove(\"Unannotated\")\n",
    "                species = set([designer_species[curr.id].strip() if curr.id in designer_species \\\n",
    "                               else \"\" for curr in SeqIO.parse(seq_file, \"fasta\")])\n",
    "                species = list(species)\n",
    "                species.remove(\"\")\n",
    "                species.remove(\"Unannotated\")\n",
    "                file_size = os.path.getsize(seq_file)\n",
    "            \n",
    "                mmetsp_group = \"B\"\n",
    "                if \"100k\" in jeukebox_dir:\n",
    "                    mmetsp_group = \"A\"\n",
    "\n",
    "                curr_df = pd.DataFrame({\"jEUKebox\": [jeukebox_dir],\n",
    "                                        \"DesignerSize\": file_size,\n",
    "                                        \"DesignerContigs\": contig_no,\n",
    "                                        \"SeqID\": seq_id,\n",
    "                                        \"Coverage\": coverage,\n",
    "                                        \"Community\": comm_num,\n",
    "                                        \"MMETSPGroup\": mmetsp_group,\n",
    "                                        \"Species\": \"-\".join(sorted(species)),\n",
    "                                        \"NumSpecies\": len(species),\n",
    "                                        \"Genera\": \"-\".join(sorted(genera)),\n",
    "                                        \"NumGenera\": len(genera),\n",
    "                                        # \"KOs\": kegg_kos,\n",
    "                                        \"NumKOs\": len(kegg_kos)})\n",
    "                file_sizes = pd.concat([file_sizes,curr_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jEUKebox-Trial3-CommB passed prot clust\n",
      "jEUKebox-Trial2-CommB passed prot clust\n",
      "jEUKebox-Trial4-100k passed prot clust\n",
      "jEUKebox-Trial2-100k passed prot clust\n",
      "jEUKebox-Trial1-CommB passed prot clust\n",
      "jEUKebox-Trial3-100k passed prot clust\n",
      "jEUKebox-Trial1-100k passed prot clust\n",
      "jEUKebox-Trial4-CommB passed prot clust\n"
     ]
    }
   ],
   "source": [
    "### Read in BLAST results on CAG ###\n",
    "\n",
    "def count_set(x):\n",
    "    x = x.dropna()\n",
    "    y = []\n",
    "    [y.extend(curr.split(\"-\")) for curr in x]\n",
    "    try:\n",
    "        len(sorted(list(set(y))))\n",
    "    except: \n",
    "        print(y,flush=True)\n",
    "    return len(sorted(list(set(y))))\n",
    "output_dir=\"two_way_contigs\" #four_way_contigs\n",
    "num_in_common = 2\n",
    "os.system(\"mkdir -p \" + output_dir)\n",
    "## READ IN EUKRHYTHMIC DATA##\n",
    "jeukebox_dirs = [curr for curr in os.listdir(base_dir) if \"jEUKebox\" in curr]\n",
    "all_with_blast_eval_10_2 = pd.DataFrame()\n",
    "\n",
    "def create_set(x):\n",
    "    x = x.dropna()\n",
    "    y = []\n",
    "    [y.extend(curr.split(\"-\")) for curr in x]\n",
    "    return \"-\".join(sorted(list(set(y))))\n",
    "\n",
    "def count_set(x):\n",
    "    x = x.dropna()\n",
    "    y = []\n",
    "    [y.extend(curr.split(\"-\")) for curr in x]\n",
    "    try:\n",
    "        len(sorted(list(set(y))))\n",
    "    except: \n",
    "        print(y,flush=True)\n",
    "    return len(sorted(list(set(y))))\n",
    "\n",
    "for jeukebox_dir in jeukebox_dirs:\n",
    "    sourmash_file = os.path.join(base_dir, jeukebox_dir, \"sourmash_MMETSP\", \"all.csv\")\n",
    "    #if jeukebox_dir == \"jEUKebox-Trial2-CommB\":\n",
    "    #    continue\n",
    "    #print(jeukebox_dir,\"starting\")\n",
    "    if os.path.isfile(sourmash_file):\n",
    "        \n",
    "        if not os.path.isdir(os.path.join(base_dir, jeukebox_dir, \n",
    "                             \"sourmash_MMETSP\")):\n",
    "            continue\n",
    "        prot_clust_dir = os.path.join(base_dir, jeukebox_dir,\n",
    "                                      \"eukrhythmic_assembly\",\n",
    "                                      \"intermediate-files\",\n",
    "                                      \"03-merge\", \"07-CAG\")\n",
    "        prot_proteins_clust_dir = os.path.join(base_dir, jeukebox_dir,\n",
    "                                      \"eukrhythmic_assembly\",\n",
    "                                      \"intermediate-files\",\n",
    "                                      \"04-compare\", \"08-CAG-proteins\")\n",
    "        if not os.path.isdir(prot_clust_dir):\n",
    "            continue\n",
    "            \n",
    "        print(jeukebox_dir,\"passed prot clust\",flush=True)\n",
    "        cluster_results = pd.DataFrame()\n",
    "        for sim_file in os.listdir(prot_clust_dir):\n",
    "            if \"tsv\" not in sim_file:\n",
    "                continue\n",
    "            fasta_file=sim_file.split(\".tsv\")[0] + \".fasta\"\n",
    "            ## WHAT'S INSIDE THE CAG FINAL CONTIGS??\n",
    "            cluster_result = pd.read_csv(os.path.join(prot_clust_dir,\n",
    "                                                      sim_file),sep=\"\\t\",\n",
    "                                        header=None,names=[\"Representative\",\"Member\"])\n",
    "            comm_num = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "            cluster_result[\"Community\"] = int(sim_file.split(\"_merged\")[0].split(\"_\")[-1])\n",
    "            cluster_result[\"Name\"] = jeukebox_dir\n",
    "            cluster_result[\"Assembler_Rep\"] = [curr.split(\"_\")[0] for curr in cluster_result.Representative]\n",
    "            cluster_result[\"Assembler_Mem\"] = [curr.split(\"_\")[0] for curr in cluster_result.Member]\n",
    "            \n",
    "            four_way_contigs = cluster_result.groupby([\"Community\",\"Name\",\"Representative\",\n",
    "                                                       \"Assembler_Rep\"]).agg({\"Assembler_Mem\": [count_set,create_set]}).reset_index()\n",
    "            four_way_contigs.columns = ['_'.join(col).strip() for col in four_way_contigs.columns.values]\n",
    "            blast_file = pd.read_csv(os.path.join(\"/vortexfs1/omics/alexander/akrinos/\"+\\\n",
    "                                                  \"2021-testing-eukrhythmic/eukrhythmic-eLife/\"+\\\n",
    "                                                  \"snakemake-workflows/blast-snake/eval_10_2_blast_top_1\",jeukebox_dir,\n",
    "                                                  \"rhythmic_sim_raw_reads_\" + \\\n",
    "                                                  str(comm_num) + \"_euk_designer_assembly_\" + str(comm_num),\n",
    "                                                 \"blast_formatted.reduced.out\"),\n",
    "                                     sep = \"\\t\") #, header = None,\n",
    "                                     #names=[\"qseqid\",\"sseqid\",\"pident\",\"length\",\"mismatch\",\n",
    "                                     #       \"gapopen\",\"qstart\",\"qend\",\"sstart\",\"send\",\n",
    "                                     #       \"evalue\",\"bitscore\"])\n",
    "            list_ids = [curr.id.split(\".\")[0].split(\"sim_raw_reads_\"+str(comm_num)+\"_\")[-1] for curr in \\\n",
    "                        SeqIO.parse(os.path.join(prot_proteins_clust_dir,\n",
    "                                                 \"sim_raw_reads_\" + str(comm_num) + \"_CAG.fasta.transdecoder.pep\"),\"fasta\")]\n",
    "            protein_df = pd.DataFrame({\"Protein\": list_ids, \"BlastMatch\": \"No\"})\n",
    "            \n",
    "            \n",
    "            blast_file[\"RepresentativeFix\"] = [str(curr).split(\".\")[0].split(\"sim_raw_reads_\"+str(comm_num)+\"_\")[-1] for \\\n",
    "                                    curr in blast_file[\"qseqid\"]]\n",
    "            \n",
    "            blast_file = pd.merge(blast_file,protein_df,how=\"right\",left_on=\"RepresentativeFix\",right_on=\"Protein\")\n",
    "            blast_file.loc[blast_file.qseqid == blast_file.qseqid,\"BlastMatch\"] = \"Yes\"\n",
    "            blast_file[\"qseqid\"] = [str(curr).split(\".\")[0].split(\"sim_raw_reads_\"+str(comm_num)+\"_\")[-1] for \\\n",
    "                                    curr in blast_file[\"qseqid\"]]\n",
    "            four_way_contigs[\"RepresentativeFix\"] = [str(curr).split(\".\")[0].split(\"sim_raw_reads_\"+str(comm_num)+\"_\")[-1] for \\\n",
    "                                    curr in four_way_contigs[\"Representative_\"]]\n",
    "            combined_blast = pd.merge(blast_file,four_way_contigs,right_on=\"RepresentativeFix\",left_on=\"Protein\",\n",
    "                                      how = \"outer\")\n",
    "            combined_blast.loc[combined_blast.BlastMatch != combined_blast.BlastMatch,\"BlastMatch\"] = \"NoProtein\"\n",
    "            combined_blast.loc[combined_blast.BlastMatch != combined_blast.BlastMatch,\"pident\"] = -1\n",
    "            all_with_blast_eval_10_2 = pd.concat([all_with_blast_eval_10_2,combined_blast])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assembler_Mem_create_set</th>\n",
       "      <th>pident_cat</th>\n",
       "      <th>Name_</th>\n",
       "      <th>pident</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>megahit</td>\n",
       "      <td>Above75</td>\n",
       "      <td>jEUKebox-Trial1-100k</td>\n",
       "      <td>15488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>megahit</td>\n",
       "      <td>Above75</td>\n",
       "      <td>jEUKebox-Trial1-CommB</td>\n",
       "      <td>13790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>megahit</td>\n",
       "      <td>Above75</td>\n",
       "      <td>jEUKebox-Trial2-100k</td>\n",
       "      <td>19222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>megahit</td>\n",
       "      <td>Above75</td>\n",
       "      <td>jEUKebox-Trial2-CommB</td>\n",
       "      <td>9740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>megahit</td>\n",
       "      <td>Above75</td>\n",
       "      <td>jEUKebox-Trial3-100k</td>\n",
       "      <td>16936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>trinity</td>\n",
       "      <td>Missing</td>\n",
       "      <td>jEUKebox-Trial2-CommB</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>trinity</td>\n",
       "      <td>Missing</td>\n",
       "      <td>jEUKebox-Trial3-100k</td>\n",
       "      <td>2863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>trinity</td>\n",
       "      <td>Missing</td>\n",
       "      <td>jEUKebox-Trial3-CommB</td>\n",
       "      <td>2454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>trinity</td>\n",
       "      <td>Missing</td>\n",
       "      <td>jEUKebox-Trial4-100k</td>\n",
       "      <td>2162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>trinity</td>\n",
       "      <td>Missing</td>\n",
       "      <td>jEUKebox-Trial4-CommB</td>\n",
       "      <td>1853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>480 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Assembler_Mem_create_set pident_cat                  Name_  pident\n",
       "0                    megahit    Above75   jEUKebox-Trial1-100k   15488\n",
       "1                    megahit    Above75  jEUKebox-Trial1-CommB   13790\n",
       "2                    megahit    Above75   jEUKebox-Trial2-100k   19222\n",
       "3                    megahit    Above75  jEUKebox-Trial2-CommB    9740\n",
       "4                    megahit    Above75   jEUKebox-Trial3-100k   16936\n",
       "..                       ...        ...                    ...     ...\n",
       "475                  trinity    Missing  jEUKebox-Trial2-CommB    1777\n",
       "476                  trinity    Missing   jEUKebox-Trial3-100k    2863\n",
       "477                  trinity    Missing  jEUKebox-Trial3-CommB    2454\n",
       "478                  trinity    Missing   jEUKebox-Trial4-100k    2162\n",
       "479                  trinity    Missing  jEUKebox-Trial4-CommB    1853\n",
       "\n",
       "[480 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_with_blast_filled = all_with_blast_eval_10_2.fillna({'pident':0})\n",
    "all_with_blast_filled = all_with_blast_filled[all_with_blast_filled.pident != \"pident\"]\n",
    "all_with_blast_filled[\"num_pident\"] = all_with_blast_filled[\"pident\"].astype(float)\n",
    "\n",
    "all_with_blast_filled[\"pident_cat\"] = [\"Missing\" if num_curr == 0 else \"Above75\" if num_curr > 75 else \"Below75\" if num_curr > 50 else \"Below50\" for num_curr in all_with_blast_filled.num_pident]\n",
    "num_pident_track = all_with_blast_filled.groupby([\"Assembler_Mem_count_set\",\"Name_\",\"pident_cat\"])[\"num_pident\"].count().reset_index()\n",
    "all_with_blast_filled.groupby([\"Assembler_Mem_create_set\",\"pident_cat\",\"Name_\"])[\"pident\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_with_blast_filled.groupby([\"Assembler_Mem_create_set\",\"pident_cat\",\"Name_\",\"Community_\"])[\"pident\"].count().reset_index().\\\n",
    "    groupby([\"Assembler_Mem_create_set\",\"pident_cat\"])[\"pident\"].agg([\"mean\",\"std\"])\\\n",
    "    .reset_index().to_csv(os.path.join(\"..\",\"data-output\", \"all_with_blast_filled.\" + str(date.today()) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_true_ans = pd.merge(compared_species,file_sizes[[\"Community\",\"MMETSPGroup\",\"Genera\",\"jEUKebox\"]],\n",
    "         left_on = [\"Community\",\"MMETSPGroup\",\"Name\"],\n",
    "         right_on = [\"Community\",\"MMETSPGroup\",\"jEUKebox\"])\n",
    "\n",
    "check_true_ans[\"Correct\"] = [\"Unannotated\" if (gen == \"Unannotated\") | (gen == \"-\") | (gen == \"Uncertain\") else \\\n",
    "                             \"Match\" if (gen in genera) else \"Conflict\" for gen,genera in zip(check_true_ans.Genus,\n",
    "                                                                                      check_true_ans.Genera)]\n",
    "\n",
    "def create_list_set(x):\n",
    "    return \"-\".join(sorted(list(set(x))))\n",
    "\n",
    "def measure_list_set(x):\n",
    "    return len(list(set(x)))\n",
    "\n",
    "count_genera = pd.melt(check_true_ans, value_vars = [\"DesignerGenusTPM\",\"CAGGenusTPM\"],\n",
    "        id_vars=[\"Community\",\"MMETSPGroup\",\"Correct\",\"Name\",\"Genus\"],value_name=\"TPM\",var_name=\"Source\").\\\n",
    "        groupby([\"Community\",\"MMETSPGroup\",\"Correct\",\"Source\",\"Name\",\"Genus\"])[\"TPM\"].sum().reset_index()\n",
    "\n",
    "count_genera = count_genera[count_genera.TPM != 0]\n",
    "count_genera = count_genera.groupby([\"Community\",\"MMETSPGroup\",\"Correct\",\"Name\",\"Source\"]).\\\n",
    "    agg({\"Genus\":[create_list_set,measure_list_set]}).reset_index()\n",
    "\n",
    "count_genera.columns = [' '.join(col).strip() for col in count_genera.columns.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_uncorrect = pd.melt(check_true_ans, value_vars = [\"DesignerGenusTPM\",\"CAGGenusTPM\"],\n",
    "        id_vars=[\"Community\",\"MMETSPGroup\",\"Correct\",\"Name\"],value_name=\"TPM\",var_name=\"Source\").\\\n",
    "        groupby([\"Community\",\"MMETSPGroup\",\"Correct\",\"Source\",\"Name\"])[\"TPM\"].sum().reset_index()\n",
    "correct_uncorrect[\"Source\"] = [\"reassembly\" if \"CAG\" in curr else \"designer\" for curr in correct_uncorrect.Source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_ko_incidence = eggnog_all.assign(KEGG_ko=eggnog_all.KEGG_ko.str.split(\",\")).explode('KEGG_ko').\\\n",
    "    groupby([\"KEGG_ko\",\"Source\",\"jEUKebox\",\"MMETSPGroup\"])[\"query\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_term_incidence = eggnog_all.assign(GOs=eggnog_all.GOs.str.split(\",\")).explode('GOs').\\\n",
    "    groupby([\"GOs\",\"Source\",\"jEUKebox\",\"MMETSPGroup\"])[\"query\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_ko_incidence_plot = kegg_ko_incidence.pivot_table(index = [\"KEGG_ko\",\"jEUKebox\",\"MMETSPGroup\"],\n",
    "                                                 columns = \"Source\", \n",
    "                                                 values = \"query\").fillna(0).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_cats = all_results.groupby([\"Name\",\"Community\",\"Representative\"])[\"Assembler_Mem\"].\\\n",
    "    apply(lambda x: \"-\".join(sorted(list(set(x))))).reset_index().groupby([\"Name\",\"Community\",\"Assembler_Mem\"]).count().\\\n",
    "    reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_results' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ffcddff30395>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## WRITE OUT RESULTS FOR USE ELSEWHERE ##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"data-output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all_results.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mall_eukulele_compare\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"data-output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all_eukulele_compare.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mall_eukulele_designer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"data-output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all_eukulele_designer.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_compared_designer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"..\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"data-output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"all_compared_designer.\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoday\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_results' is not defined"
     ]
    }
   ],
   "source": [
    "## WRITE OUT RESULTS FOR USE ELSEWHERE ##\n",
    "all_results.to_csv(os.path.join(\"..\",\"data-output\", \"all_results.\" + str(date.today()) + \".csv\"))\n",
    "all_eukulele_compare.to_csv(os.path.join(\"..\",\"data-output\", \"all_eukulele_compare.\" + str(date.today()) + \".csv\"))\n",
    "all_eukulele_designer.to_csv(os.path.join(\"..\",\"data-output\", \"all_eukulele_designer.\" + str(date.today()) + \".csv\"))\n",
    "all_compared_designer.to_csv(os.path.join(\"..\",\"data-output\", \"all_compared_designer.\" + str(date.today()) + \".csv\"))\n",
    "compared_species.to_csv(os.path.join(\"..\",\"data-output\", \"compared_species.\" + str(date.today()) + \".csv\"))\n",
    "count_cluster_all.to_csv(os.path.join(\"..\",\"data-output\", \"count_cluster_all.\" + str(date.today()) + \".csv\"))\n",
    "eukulele_prot_annots.to_csv(os.path.join(\"..\",\"data-output\", \"eukulele_prot_annots.\" + str(date.today()) + \".csv\"))\n",
    "all_eggnog_CAG.to_csv(os.path.join(\"..\",\"data-output\", \"all_eggnog_CAG.\" + str(date.today()) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eggnog_CAG.to_csv(os.path.join(\"..\",\"data-output\", \"all_eggnog_CAG.\" + str(date.today()) + \".csv\"))\n",
    "all_eggnog_designer.to_csv(os.path.join(\"..\",\"data-output\", \"all_eggnog_designer.\" + str(date.today()) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eukulele_designer.to_csv(os.path.join(\"..\",\"data-output\", \"all_eukulele_designer.\" + str(date.today()) + \".csv\"))\n",
    "all_EUKulele_CAG.to_csv(os.path.join(\"..\",\"data-output\", \"all_EUKulele_CAG.\" + str(date.today()) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cag_sizes.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"cag_sizes.\" + str(date.today()) + \".csv\"))\n",
    "designer_sizes.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"designer_sizes.\" + str(date.today()) + \".csv\"))\n",
    "\n",
    "compared_sizes.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"compared_sizes.\" + str(date.today()) + \".csv\"))\n",
    "\n",
    "concat_sizes.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"concat_sizes.\" + str(date.today()) + \".csv\"))\n",
    "kegg_ko_incidence.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"kegg_ko_incidence.\" + str(date.today()) + \".csv\"))\n",
    "count_genera.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"count_genera.\" + str(date.today()) + \".csv\"))\n",
    "correct_uncorrect.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"correct_uncorrect.\" + str(date.today()) + \".csv\"))\n",
    "compared_species.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"compared_species.\" + str(date.today()) + \".csv\"))\n",
    "eggnog_prot_annots.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"eggnog_prot_annots.\" + str(date.today()) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_cats.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"number_cats.\" + str(date.today()) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_genera.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"count_genera.\" + str(date.today()) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_uncorrect.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"correct_uncorrect.\" + str(date.today()) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "compared_species.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"compared_species.\" + str(date.today()) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eggnog_prot_annots.to_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"eggnog_prot_annots.\" + str(date.today()) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## READ BACK IN RESULTS ##\n",
    "curr_date = \"2022-01-24\"#date.today()\n",
    "all_results = pd.read_csv(os.path.join(\"..\",\"data-output\", \"all_results.\" + str(curr_date) + \".csv\"))\n",
    "all_eukulele_compare = pd.read_csv(os.path.join(\"..\",\"data-output\", \"all_eukulele_compare.\" + str(curr_date) + \".csv\"))\n",
    "all_compared_designer = pd.read_csv(os.path.join(\"..\",\"data-output\", \"all_compared_designer.\" + str(curr_date) + \".csv\"))\n",
    "count_cluster_all = pd.read_csv(os.path.join(\"..\",\"data-output\", \"count_cluster_all.\" + str(curr_date) + \".csv\"))\n",
    "eukulele_prot_annots = pd.read_csv(os.path.join(\"..\",\"data-output\", \"eukulele_prot_annots.\" + str(curr_date) + \".csv\"))\n",
    "cag_sizes=pd.read_csv(os.path.join(\"..\",\"data-output\", \n",
    "                                    \"cag_sizes.\" + str(curr_date) + \".csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scplotenv",
   "language": "python",
   "name": "scplotenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
